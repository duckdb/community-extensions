extension:
  name: sitemap
  description: Parse XML sitemaps from websites with automatic discovery via robots.txt
  version: 0.1.0
  language: C++
  build: cmake
  license: MIT
  requires_toolchains: "libxml2;zlib"
  maintainers:
    - onnimonni

repo:
  github: midwork-finds-jobs/duckdb-sitemap
  ref: efc9f7bbe21e9a3fa49c5e7b4779b84b8112969c

docs:
  hello_world: |
    -- Get all URLs from a sitemap
    SELECT * FROM sitemap_urls('https://example.com');

    -- Filter specific URLs
    SELECT * FROM sitemap_urls('https://example.com')
    WHERE url LIKE '%/blog/%';

    -- Count URLs by type
    SELECT
        CASE
            WHEN url LIKE '%/product/%' THEN 'product'
            WHEN url LIKE '%/blog/%' THEN 'blog'
            ELSE 'other'
        END as type,
        count(*) as count
    FROM sitemap_urls('https://example.com')
    GROUP BY type;

  extended_description: |
    The sitemap extension provides a table function for parsing XML sitemaps from websites.
    It automatically discovers sitemaps via robots.txt and supports recursive sitemap index traversal.

    Features:
    - Automatic sitemap discovery from /robots.txt
    - Sitemap index support (nested sitemaps)
    - Retry logic with exponential backoff
    - Respects Retry-After header on 429 responses
    - Gzip decompression for .xml.gz files
    - Multiple namespace support (standard + Google schemas)
    - SQL filtering with WHERE clauses

    The function returns a table with columns:
    - url: Page URL (VARCHAR)
    - lastmod: Last modification date (VARCHAR, optional)
    - changefreq: Change frequency hint (VARCHAR, optional)
    - priority: Priority hint 0.0-1.0 (VARCHAR, optional)

    Options:
    - follow_robots (BOOLEAN): Parse robots.txt first (default: true)
    - max_depth (INTEGER): Max sitemap index nesting (default: 3)
    - max_retries (INTEGER): Max retry attempts (default: 5)
    - backoff_ms (INTEGER): Initial backoff in ms (default: 100)
    - max_backoff_ms (INTEGER): Max backoff cap in ms (default: 30000)

    Example with options:
    ```sql
    SELECT * FROM sitemap_urls(
        'https://example.com',
        follow_robots := true,
        max_depth := 5,
        max_retries := 10
    ) WHERE url LIKE '%/product/%';
    ```

    Compose with http_request to fetch page content:
    ```sql
    SELECT s.url, h.body
    FROM sitemap_urls('https://example.com') s
    JOIN LATERAL (SELECT * FROM http_get(s.url)) h ON true
    WHERE s.url LIKE '%/product/%'
    LIMIT 10;
    ```
