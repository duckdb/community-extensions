docs:
  extended_description: "## Open Prompt Extension\nThe `open_prompt()` community extension\
    \ is shamelessly inspired by the Motherduck `prompt()` but focused on self-hosted\
    \ usage.\n\n> For examples and instructions check out the `open_prompt()` [README](https://github.com/quackscience/duckdb-extension-openprompt)\n\
    \n### Configuration\nSetup the completions API URL configuration w/ optional auth\
    \ token and model name\n\n```\nSET VARIABLE openprompt_api_url = 'http://localhost:11434/v1/chat/completions';\n\
    SET VARIABLE openprompt_api_token = 'your_api_key_here';\nSET VARIABLE openprompt_model_name\
    \ = 'qwen2.5:0.5b';\n```\n\nAlternatively the following ENV variables can be used\
    \ at runtime\n\n```\nOPEN_PROMPT_API_URL='http://localhost:11434/v1/chat/completions'\n\
    OPEN_PROMPT_API_TOKEN='your_api_key_here'\nOPEN_PROMPT_MODEL_NAME='qwen2.5:0.5b'\n\
    OPEN_PROMPT_API_TIMEOUT='30'\n```\n\nFor persistent usage, configure parameters\
    \ using DuckDB `SECRETS`\n\n```sql\nCREATE PERSISTENT SECRET IF NOT EXISTS open_prompt\
    \ (\n      TYPE open_prompt,\n      PROVIDER config,\n      api_token 'your-api-token',\n\
    \      api_url 'http://localhost:11434/v1/chat/completions',\n      model_name\
    \ 'qwen2.5:0.5b',\n      api_timeout '30'\n  );\n```"
  hello_world: "-- Configure the required parameters to access OpenAI Completions\
    \ compatible APIs\nD CREATE SECRET IF NOT EXISTS open_prompt (\n      TYPE open_prompt,\n\
    \      PROVIDER config,\n      api_token 'your-api-token',\n      api_url 'http://localhost:11434/v1/chat/completions',\n\
    \      model_name 'qwen2.5:0.5b',\n      api_timeout '30'\n  );\n\n-- Prompt any\
    \ OpenAI Completions API form your query\nD SELECT open_prompt('Write a one-line\
    \ poem about ducks') AS response;\n\u250C\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2510\n\u2502                    response                    \u2502\
    \n\u2502                    varchar                     \u2502\n\u251C\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Ducks quacking at dawn,\
    \ swimming in the light. \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2518\n\n-- Prompt requesting JSON Structured Output for ChatGPT,\
    \ LLama3, etc\nSET VARIABLE openprompt_model_name = 'llama3.2:3b';\nSELECT open_prompt('I\
    \ want ice cream', json_schema := '{\n   \"type\": \"object\",\n   \"properties\"\
    : {\n     \"summary\": { \"type\": \"string\" },\n     \"sentiment\": { \"type\"\
    : \"string\", \"enum\": [\"pos\", \"neg\", \"neutral\"] }\n   },\n   \"required\"\
    : [\"summary\", \"sentiment\"],\n   \"additionalProperties\": false\n }');\n\n\
    -- Use Custom System Prompt to request JSON Output in smaller models\nSET VARIABLE\
    \ openprompt_model_name = 'qwen2.5:1.5b';\nSELECT open_prompt('I want ice cream.',\
    \ system_prompt:='Response MUST be JSON with the following schema: {\n       \"\
    type\": \"object\",\n       \"properties\": {\n         \"summary\": { \"type\"\
    : \"string\" },\n         \"sentiment\": { \"type\": \"string\", \"enum\": [\"\
    pos\", \"neg\", \"neutral\"] }\n       },\n       \"required\": [\"summary\",\
    \ \"sentiment\"],\n       \"additionalProperties\": false\n     }');\n"
extension:
  build: cmake
  description: Interact with LLMs with a simple DuckDB Extension
  excluded_platforms: windows_amd64_rtools
  language: C++
  license: MIT
  maintainers:
  - lmangani
  - akvlad
  name: open_prompt
  version: '2025120401'
repo:
  github: quackscience/duckdb-extension-openprompt
  ref: 5328a2ff7100887263259ccc5ad8c03b8c6bc58a
  ref_next: b9b0d6884f43e515fda0977fc891598d874f490f
