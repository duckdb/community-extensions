extension:
  name: crawler
  description: SQL-native web crawler with HTML extraction and MERGE support
  version: '2026020501'
  language: C++
  build: cmake
  license: MIT
  maintainers:
    - onnimonni

  requires_toolchains: rust
  excluded_platforms: "windows_amd64_mingw;wasm_mvp;wasm_eh;wasm_threads"

repo:
  github: midwork-finds-jobs/duckdb-crawler
  ref: f0aad857435a2ce138c567e8af11f9d4f8ae0c25

docs:
  hello_world: |
    SELECT url, jq(html.document, 'h1').text as title
    FROM crawl(['https://example.com']);
  extended_description: |
    The crawler extension provides SQL-native web crawling capabilities for DuckDB.

    Features:
    - `crawl()` table function with automatic rate limiting and robots.txt compliance
    - `crawl_url()` for LATERAL joins
    - `sitemap()` for XML sitemap parsing
    - `read_html()` for Google Sheets-style IMPORTHTML (tables, lists, JS variables)
    - `jq()` and `htmlpath()` functions for CSS selector-based extraction
    - `html.readability` for article extraction
    - `html.schema` for JSON-LD/microdata parsing
    - `CRAWLING MERGE INTO` syntax for upsert operations

    Example with read_html (like Google Sheets =IMPORTHTML):
    ```sql
    SELECT * FROM read_html('https://en.wikipedia.org/wiki/...', 'table.wikitable', 1);
    SELECT * FROM read_html('https://example.com/page', 'js=jobs');
    ```

    Example with extraction:
    ```sql
    SELECT
        url,
        jq(html.document, '.price', 'data-amount') as price,
        html.readability.title as article_title
    FROM crawl(['https://example.com/products']);
    ```

    Example with MERGE:
    ```sql
    CRAWLING MERGE INTO pages
    USING crawl(['https://example.com']) AS src
    ON (src.url = pages.url)
    WHEN MATCHED THEN UPDATE BY NAME
    WHEN NOT MATCHED THEN INSERT BY NAME;
    ```

    For full documentation see: https://github.com/midwork-finds-jobs/duckdb-crawler
